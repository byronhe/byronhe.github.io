<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>用 DAT 重实现 CppJieba 中文分词算法，降低 99% 内存消耗 - Tech Ideas</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="byronhe" /><meta name="description" content="一，问题背景 中文分词应用比较广泛的开源算法，是 jieba 结巴分词，结巴分词较高性能的实现是 C&#43;&#43; 版本的 CppJieba : https://github.com/yanyiwu/cppjieba
在实际使用 CppJieba 的过程中，我们发现 CppJieba 的内存占用比较高。
比如对一个 76W 词 大小 11MB 的词典 ，加载 2份 （比如为了支持平滑改动用户词典）就需要耗费 505MB内存。
这对一些多进程的后台服务，浪费大量内存，难以接受，因此这里希望削减内存耗费。
经过初步调查，确定改进方法，然后动手改造，最终把 505MB 缩减到了 4.7MB ，实现了 99% 内存降低。
此处也有 issue 讨论 https://github.com/yanyiwu/cppjieba/issues/3
代码稍后可能会开源出来。
" /><meta name="keywords" content="search ,  segment,  分词,  algorithm,  server" />






<meta name="generator" content="Hugo 0.68.3 with theme even" />


<link rel="canonical" href="https://blog.helong.info/post/2019/11/25/cppjieba-darts-dat-memory_optimize/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">


<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="用 DAT 重实现 CppJieba 中文分词算法，降低 99% 内存消耗" />
<meta property="og:description" content="一，问题背景
中文分词应用比较广泛的开源算法，是 jieba 结巴分词，结巴分词较高性能的实现是 C&#43;&#43; 版本的 CppJieba :
https://github.com/yanyiwu/cppjieba
在实际使用 CppJieba 的过程中，我们发现 CppJieba 的内存占用比较高。
比如对一个 76W 词 大小 11MB 的词典 ，加载 2份 （比如为了支持平滑改动用户词典）就需要耗费 505MB内存。
这对一些多进程的后台服务，浪费大量内存，难以接受，因此这里希望削减内存耗费。
经过初步调查，确定改进方法，然后动手改造，最终把 505MB 缩减到了 4.7MB ，实现了 99% 内存降低。
此处也有 issue 讨论 https://github.com/yanyiwu/cppjieba/issues/3
代码稍后可能会开源出来。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://blog.helong.info/post/2019/11/25/cppjieba-darts-dat-memory_optimize/" />
<meta property="article:published_time" content="2019-11-25T00:00:00+00:00" />
<meta property="article:modified_time" content="2019-11-25T00:00:00+00:00" />
<meta itemprop="name" content="用 DAT 重实现 CppJieba 中文分词算法，降低 99% 内存消耗">
<meta itemprop="description" content="一，问题背景
中文分词应用比较广泛的开源算法，是 jieba 结巴分词，结巴分词较高性能的实现是 C&#43;&#43; 版本的 CppJieba :
https://github.com/yanyiwu/cppjieba
在实际使用 CppJieba 的过程中，我们发现 CppJieba 的内存占用比较高。
比如对一个 76W 词 大小 11MB 的词典 ，加载 2份 （比如为了支持平滑改动用户词典）就需要耗费 505MB内存。
这对一些多进程的后台服务，浪费大量内存，难以接受，因此这里希望削减内存耗费。
经过初步调查，确定改进方法，然后动手改造，最终把 505MB 缩减到了 4.7MB ，实现了 99% 内存降低。
此处也有 issue 讨论 https://github.com/yanyiwu/cppjieba/issues/3
代码稍后可能会开源出来。">
<meta itemprop="datePublished" content="2019-11-25T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-11-25T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="912">



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="用 DAT 重实现 CppJieba 中文分词算法，降低 99% 内存消耗"/>
<meta name="twitter:description" content="一，问题背景
中文分词应用比较广泛的开源算法，是 jieba 结巴分词，结巴分词较高性能的实现是 C&#43;&#43; 版本的 CppJieba :
https://github.com/yanyiwu/cppjieba
在实际使用 CppJieba 的过程中，我们发现 CppJieba 的内存占用比较高。
比如对一个 76W 词 大小 11MB 的词典 ，加载 2份 （比如为了支持平滑改动用户词典）就需要耗费 505MB内存。
这对一些多进程的后台服务，浪费大量内存，难以接受，因此这里希望削减内存耗费。
经过初步调查，确定改进方法，然后动手改造，最终把 505MB 缩减到了 4.7MB ，实现了 99% 内存降低。
此处也有 issue 讨论 https://github.com/yanyiwu/cppjieba/issues/3
代码稍后可能会开源出来。"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Tech Ideas</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Tech Ideas</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">用 DAT 重实现 CppJieba 中文分词算法，降低 99% 内存消耗</h1>

      <div class="post-meta">
        <span class="post-time"> 2019-11-25 </span>
        <div class="post-category">
            <a href="/categories/search/"> search </a>
            <a href="/categories/nlp/"> NLP </a>
            <a href="/categories/server/"> server </a>
            </div>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#一问题背景">一，问题背景</a></li>
        <li><a href="#二实现过程">二，实现过程</a>
          <ul>
            <li><a href="#二1--查内存分布">二.1  查内存分布</a></li>
            <li><a href="#二2-优化方案">二.2 优化方案</a></li>
            <li><a href="#二3-其他问题">二.3 其他问题</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h2 id="一问题背景">一，问题背景</h2>
<p>中文分词应用比较广泛的开源算法，是 <a href="https://github.com/fxsjy/jieba">jieba 结巴分词</a>，结巴分词较高性能的实现是 C++ 版本的 CppJieba :
<a href="https://github.com/yanyiwu/cppjieba">https://github.com/yanyiwu/cppjieba</a></p>
<p>在实际使用 CppJieba 的过程中，我们发现 CppJieba 的内存占用比较高。</p>
<p>比如对一个 76W 词 大小 11MB 的词典 ，加载 2份 （比如为了支持平滑改动用户词典）就需要耗费 505MB内存。</p>
<p>这对一些多进程的后台服务，浪费大量内存，难以接受，因此这里希望削减内存耗费。</p>
<p>经过初步调查，确定改进方法，然后动手改造，<strong>最终把 505MB 缩减到了 4.7MB ，实现了 99% 内存降低</strong>。</p>
<p>此处也有 issue 讨论 <a href="https://github.com/yanyiwu/cppjieba/issues/3">https://github.com/yanyiwu/cppjieba/issues/3</a></p>
<p>代码稍后可能会开源出来。</p>
<h2 id="二实现过程">二，实现过程</h2>
<h3 id="二1--查内存分布">二.1  查内存分布</h3>
<p>第一步先用 jemalloc 的 memory profiler 工具查看内存耗费在哪里，</p>
<ol>
<li>改一下 CppJieba  的  test/demo.cpp， 链接 jemalloc，编译成二进制  jieba_test</li>
<li>然后设置环境变量
<code>export MALLOC_CONF=&quot;prof:true,prof_prefix:mem_prof/mem_profile_je.out,lg_prof_interval:20,lg_prof_sample:20&quot;</code></li>
<li>然后  mkdir mem_prof， 并运行测试程序</li>
<li>jeprof &ndash;pdf ./jieba_test mem_prof/mem_profile_je.out.xxx.heap &gt; mem_profile.pdf</li>
</ol>
<p>打开 mem_profile.pdf ，就可以看到内存分布了</p>
<h3 id="二2-优化方案">二.2 优化方案</h3>
<p>显而易见，内存主要耗费在:</p>
<ol>
<li>Trie.hpp 中的 Trie 树构建</li>
<li>KeywordExtractor.hpp 加载  idf 词典文件。</li>
</ol>
<p>因此方案:</p>
<h4 id="1-double-array-trie-代替--cppjiebatrie">1. Double Array Trie 代替  cppjieba::Trie</h4>
<p>引入 Double Array Trie  (简称  DAT ,https://github.com/s-yata/darts-clone) , 代替 Trie.hpp 中的简单内存 Trie，并把 darts 生成的  DAT 保存到文件中，在启动时，如果已经有和词典对应的 DAT ，直接 mmap() attach 上去，即可启动。</p>
<p>经过实测发现，75万词词典，dart-clone 生成的 DAT 文件，大小只有 24MB，而且可以 mmap 挂载，多进程共享。</p>
<h4 id="2-keywordextractor">2. KeywordExtractor</h4>
<p>KeywordExtractor 是个不常用功能，直接改成支持传入空的 idfPath 和 stopWordPath, 此时不加载数据即可。</p>
<h3 id="二3-其他问题">二.3 其他问题</h3>
<h4 id="1-支持热更新保证词典和dat一致">1. 支持热更新，保证词典和DAT一致</h4>
<p>这里一个问题是，词典可能热更新，那怎么知道 DAT 文件和当前词典的内容对应？</p>
<p>我的做法是，对 默认词典文件+自定义词典文件，用文件内容算 MD5，写入 DAT 文件头部，这样打开 DAT 文件发现 MD5 不一致，就知道 DAT文件过时了，即可重建 DAT 。</p>
<p>实测发现算 MD5 还是很快的，启动时间都在 1秒 左右。</p>
<h4 id="2-代码清理">2. 代码清理</h4>
<p>另外，清理了一下代码，删掉了 Unicode.hpp 中的无用代码。
清理了 FullSegment.hpp HMMSegment.hpp MixSegment.hpp MPSegment.hpp QuerySegment.hpp 等中的重复代码。</p>
<h4 id="3-不兼容改动">3. 不兼容改动</h4>
<ul>
<li>由于 Double Array Trie 无法支持动态插入词，删除 InsertUserWord() 方法</li>
<li>FullSegment.hpp 中 maxId 的计算有 bug，做了 fix。</li>
</ul>
<p>整体改造后，代码量比原来减少 100 多行。</p>
<p>上线后效果显著。</p>
<p>当内存降低到 2-3MB 的水平后，这意味着 75W 词这种规模的大词典，可以用在手机环境。</p>
<p>比如可以在 ios 或者 Android 上做 中文/英文的切词，
这意味着可能在客户端实现体验相当良好的搜索引擎。</p>
<p>ios 上也有可用于中文的分词器 <a href="https://developer.apple.com/documentation/corefoundation/cfstringtokenizer-rf8">CFStringTokenizer</a> ，但貌似不开源。</p>
    </div>

    
<footer class="post-footer">
      
      <nav class="post-nav">
        <a class="prev" href="/post/2019/11/29/pthran-py-to-cpp-translater-in-feature-engineering/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Python 自动翻译成 C&#43;&#43; ，彻底保证离线在线特征一致</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/2019/09/18/newwords_discovery/">
            <span class="next-text nav-default">GB 规模语料上的高性能新词发现算法</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        <div id="disqus_thread"></div>
    <script type="text/javascript">
    (function() {
      
      
      if (window.location.hostname === 'localhost') return;

      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      var disqus_shortname = 'byronheblog';
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="https://github.com/byronhe" class="iconfont icon-github" title="github"></a>
  <a href="https://blog.helong.info/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2010 - 
    2020
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">byronhe</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-49290834-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>







</body>
</html>
